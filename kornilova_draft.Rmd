---
title: "andan_project"
output: html_document
date: "2025-05-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Installs
```{r installs}
library(tidyverse)
library(ggplot2)
library(plotly)
library(kableExtra)
library(factoextra)
library(vegan)
library(FactoMineR)
library(dplyr)
library(lmtest)
library(glmnet)
library(text2vec)
library(caret)
library(Matrix)
library(stringr)
library(vcd)
library(ggmosaic)
```
## Гипотезы

Датасет содержит термины игрового сленга из различных видеоигр и их классификацию по словообразовательным моделям. Проект продолжает и расширяет бакалаврскую работу, фокусируясь на определении оннотации сленговых слов и её зависимости от контекста, жанра игры, словообразовательной модели. 

Целевая переменная — Connotation (коннотация), которая принимает следующие значения: neutral, positive, negative,	ambivalent, irony/sarcasm.

Гипотезы:

H₀: Коннотация слова не зависит от части речи.
H₁: Коннотация слова зависит от части речи.

H₀: Коннотация слова не зависит от контекста.
H₁: Коннотация слова зависит от контекста.

H₀: Коннотация слова не зависит от жанра игры.
H₁: Коннотация слова зависит от жанра игры.

H₀: Коннотация слова не зависит от модели словообразования.
H₁: Коннотация слова зависит от модели словообразования.


Датасет содержит 209 примеров и 6 переменных.

Переменные:
slang word: Сленговое слово или выражение

word formation model: Модель словообразования

context: Контекст использования термина

part of speech: Часть речи

Genre of game Where it appears: Жанр игры, где встречается термин

Connotation: Коннотация (нейтральная, положительная, отрицательная)

## Описательная статистика

```{r data_reading}
df <- read.csv("gaming_slang_2.csv", stringsAsFactors = FALSE)
```


Тип данных: все переменные хранятся как текстовые (chr), что может потребовать их преобразования в факторы для анализа. Пустых значений нет.

```{r summary}
str(df)
summary(df)
sum(is.na(df))
```
```{r factors}
# Преобразуем переменные в факторы
df$word.formation.model <- as.factor(df$word.formation.model)
df$context <- as.factor(df$context)
df$part.of.speech <- as.factor(df$part.of.speech)
df$Genre.of.game.Where.it.appears <- as.factor(df$Genre.of.game.Where.it.appears)
df$Connotation <- as.factor(df$Connotation)
```

Проверка категориальных переменных выводит все уникальные значения для каждого категориального признака и помогает оценить разнообразие категорий.

```{r data_description}
cat("Уникальные значения коннотации:", levels(df$Connotation), "\n")
cat("Уникальные модели словообразования:", levels(df$word.formation.model), "\n")
cat("Уникальный контекст:", levels(df$context), "\n")
cat("Уникальные части речи:", levels(df$part.of.speech), "\n")
cat("Уникальные жанры игр:", levels(df$Genre.of.game.Where.it.appears), "\n")
```
На основе распределения можно предварительно сказать:
Токсичность и критика (negative + irony/sarcasm = 45.9%) занимают почти половину всех терминов, это говорит о том, что игровая среда часто полна экспрессивного и оценочного языка.
Позитивных и нейтральных слов меньше (около 37%), что может говорить о том, что сленг больше используется для оценки, а не для описания «обычного» или «положительного» поведения.
Высокая доля иронии подчёркивает юмористическую или язвительную природу сленга, особенно в онлайн сообществах.
Ambivalent выражения (16.7%) могут быть интересны для дальнейшего анализа — они могут меняться в зависимости от тона общения, жанра игры или даже пола игрока.

```{r connotation_distribution}
# Распределение коннотации
ggplot(df, aes(x = Connotation, fill = Connotation)) +
  geom_bar() +
  scale_fill_manual(values = c("negative" = "salmon", "neutral" = "gray", "positive" = "gold", "ambivalent" = "lightgreen", "irony/sarcasm" = "mediumorchid")) +
  labs(title = "Распределение коннотации игрового сленга",
       x = "Коннотация", y = "Количество слов") +
  theme_minimal()

table(df$Connotation)
```

```{r distribution_func}
# Создание функции для генерации таблиц распределения
create_connotation_table <- function(data, group_var) {
  data %>%
    group_by({{group_var}}, Connotation) %>%
    summarise(Count = n(), .groups = 'drop') %>%
    mutate(Percentage = round(Count / sum(Count) * 100, 1)) %>%
    pivot_wider(names_from = Connotation, 
                values_from = c(Count, Percentage),
                names_sep = "_",
                values_fill = list(Count = 0, Percentage = 0))
}
```


Существительные — наиболее частая часть речи, при этом они чаще всего несут негативную или нейтральную окраску.
Глаголы сравнительно нейтральны или негативны. Их положительная окраска встречается редко.
Прилагательные склонны к позитивной коннотации.
Наречия встречаются редко, а если встречаются, то могут были либо положительными, либо отрицаельными, либо нейтральными.

```{r connotation_pos}
# Распределение частей речи по коннотации
ggplot(df, aes(x = part.of.speech, fill = Connotation)) +
  geom_bar(position = "dodge") +
  scale_fill_manual(values = c("negative" = "salmon", "neutral" = "gray", "positive" = "gold", "ambivalent" = "lightgreen", "irony/sarcasm" = "mediumorchid")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Часть речи и коннотация")


part_of_speech_table <- df %>%
  separate_rows(part.of.speech, sep = ", ") %>%
  create_connotation_table(part.of.speech) %>%
  arrange(desc(Count_negative))

part_of_speech_table
```
Больше всего наблюдений у группы General, сбалансированный состав, но много негатива, то есть в играх всех жанров преобладает негативная коннотация. 
MOBA - второй по популярности жанр, имеет высокую долю негатива и иронии.
В MMORPG смешанные коннотации, а в FPS сильнее негатив.Strategy, RPG, Action не имеют негативную коннотацию. 
В жанрах, требующих командного взаимодействия и быстрой реакции (MOBA, FPS), негатив выражен сильнее.

```{r connotation_genres}
# Распределение жанров игр и коннотаци
ggplot(df, aes(x = Genre.of.game.Where.it.appears, fill = Connotation)) +
  geom_bar(position = "dodge") +
  scale_fill_manual(values = c("negative" = "salmon", "neutral" = "gray", "positive" = "gold", "ambivalent" = "lightgreen", "irony/sarcasm" = "mediumorchid")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Жанры игр и коннотация")



genre_table <- create_connotation_table(df, Genre.of.game.Where.it.appears) %>%
  arrange(desc(Count_negative))
genre_table
```
Суффиксация часто используется для создания негативных ярлыков
Словосложение практически универсально: оно может обозначать как негатив с иронией, так и позитив.
Метафоры выражают эмоции, создают яркие и амбивалентные смыслы, тоже универсальны.
Аббревиатуры, конверсия и акронимы в большей степени нейтральны.

```{r connotation_wc}
# Распределение моделей словообразования и коннотации
ggplot(df, aes(x = word.formation.model, fill = Connotation)) +
  geom_bar(position = "dodge") +
  scale_fill_manual(values = c("negative" = "salmon", "neutral" = "gray", "positive" = "gold", "ambivalent" = "lightgreen", "irony/sarcasm" = "mediumorchid")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Словообразование и коннотация")

formation_table <- create_connotation_table(df, word.formation.model) %>%
  arrange(desc(Count_negative))
formation_table
```
Контекст "Evaluating other users" максимально негативный контекст — почти треть всех негативных выражений здесь.
"Strategies and gameplay" - смесь коннотаций, но преобладает негатив и нейтральность.
"Game atmosphere" / "Communication" умеренно сбалансированы.
"Victory" / "Player’s role" больше позитива.
Почти полностью нейтрален контекст "In-game indicators".

```{r connotation_context}
# Распределение коннотации по контексту
ggplot(df, aes(x = context, fill = Connotation)) +
  geom_bar(position = "dodge") +
  scale_fill_manual(values = c("negative" = "salmon", "neutral" = "gray", "positive" = "gold", "ambivalent" = "lightgreen", "irony/sarcasm" = "mediumorchid")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Контекст использования слов и коннотация")

context_table <- create_connotation_table(df, context) %>%
  arrange(desc(Count_negative))
context_table
```
В датасет была добавлена новая переменная word_length, потому что это потенциально важный признак в задачах автоматического распознавания коннотации.

График ниже иллюстрирует, как длина сленговых слов распределена в зависимости от коннотации. 
Самые короткие слова у нейтральной коннотации, у них медиана длины заметно ниже (около 3).Узкий IQR показывает, что много выбросов.

Самые длинные в среднем у иронично-саркастической коннотации, у них медиана ближе к 8. У позитивной и иронично-саркастической коннотации распределение более широкое, встречаются как короткие, так и длинные слова.

У амбивалентной и негативной коннотации медиана около 7, но у амбивалентной разброс больше, чем у негативной

Нейтральные слова часто короче, возможно, потому что они более общие и часто употребимые. Ироничные/саркастические и положительные  самые длинные, что может отражать степень эмоциональной окраски или изобразительности таких слов.


```{r word_lenght}
df$word_length <- nchar(df$slang.word)

ggplot(df, aes(x = Connotation, y = word_length, fill = Connotation)) +
  geom_boxplot() +
  scale_fill_manual(values = c("negative" = "salmon", "neutral" = "gray", "positive" = "gold", "ambivalent" = "lightgreen", "irony/sarcasm" = "mediumorchid")) +
  labs(title = "Длина сленговых слов по коннотации",
       x = "Коннотация", y = "Длина слова") +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 3, color = "red") +
  theme_minimal()


df %>% 
  mutate(word_length = nchar(slang.word)) %>% 
  group_by(Connotation) %>% 
  summarise(mean_length = mean(word_length))

# Основные статистики по длине слов
summary(df$word_length)
```

## Фреквентистская статистика


Перед проведение статистических тестов нужно проверить данные на нормальность. 

```{r shapiro}
# проверка нормальности данных
shapiro.test(df$word_length)

shapiro.test(df$word_length[df$Connotation == "positive"])

shapiro.test(df$word_length[df$Connotation == "negative"])

shapiro.test(df$word_length[df$Connotation == "irony/sarcasm"])

shapiro.test(df$word_length[df$Connotation == "ambivalent"])

shapiro.test(df$word_length[df$Connotation == "neutral"])
```
Результаты проверки нормальности: 

Распределение длины слов не является нормальным, потому что p-value = 6.1e-06 < 0.05.
Распределение позитивной коннотации по длине слов также не является нормальным, потому что p-value = 0.0087 < 0.05.
Распределение негативной коннотации по длине слов можно считать нормальным, потому что p-value = 0.1348 > 0.05.
Распределение иронично-саркастичной коннотации по длине слов можно считать нормальным, потому что p-value = 0.2488 > 0.05.
Распределение амбивалентной коннотации по длине слов можно считать нормальным, потому что p-value = 0.09743 > 0.05.
Распределение нейтральной коннотации по длине слов не является нормальным, потому что p-value = 1.716e-05 < 0.05.

Можно провести t-test между negative и irony/sarcasm или negative и ambivalent коннотацией, так как они распределены нормально.


```{r t_test}
# t-test
t.test(word_length ~ Connotation, data = df %>% filter(Connotation %in% c("negative", "irony/sarcasm")))

t.test(word_length ~ Connotation, data = df %>% filter(Connotation %in% c("negative", "ambivalent")))

t.test(word_length ~ Connotation, data = df %>% filter(Connotation %in% c("irony/sarcasm", "ambivalent")))
```
Интерпретация результатов t-теста.

Высокое p-value (0.6266, 0.348, 0.195) говорит о том, что нет статистически значимого различия между средними длинами слов в группах "irony/sarcasm" и "negative", "negative" и "ambivalent", "irony/sarcasm" и "ambivalent".
Доверительный интервал у всех групп 95% и включает 0, что также подтверждает отсутствие значимого различия.
Разница в средних небольшая, но показывает, что слова с ироничной-саркастической коннотацией длиннее слов с негативной на 0.28 и длинее слов с абивалентной на 0,8, а слова с негативной коннотацией длиннее слов с амбивалентной на 0.56.

Согласно результатам Welch t-теста, гипотеза о равенстве средних длины слов в группах "irony/sarcasm" и "negative" не отвергается. Это означает, что ироничные/саркастичные, негативные и амбивалентные термины не отличаются по длине.


Для проверки других видов коннотации будет использован тест Манна-Уитни (U-тест), так как он не требует нормальности распределения, в отличие от t-теста. 

```{r u_test}
# Тест Манна-Уитни (U-тест)
connotations <- unique(df$Connotation)
pairs <- combn(connotations, 2, simplify = FALSE)

for (pair in pairs) {
  group1 <- pair[1]
  group2 <- pair[2]
  
  cat("\nТест Манна-Уитни для:", group1, "vs", group2, "\n")
  result <- wilcox.test(
    word_length ~ Connotation,
    data = df %>% filter(Connotation %in% c(group1, group2))
  )
  print(result)
}
```
Интерпретация результатов тестов Манна-Уитни.

Для большинства пар p-value больше 0.05, то есть различия статистически незначимы.
Однако были обнаружены статистически значимые различия (p < 0.05):
Слова в нейтральной группе и амбивалентной имеют значимо разную длину (0.0045 < 0.05). Значимы различия и в группе ироничные VS нейтральные (0.00018 < 0.05). Отрицательные слова имеют статистически иную длину, чем нейтральные (0.0000829 < 0.05). Различия между позитивными и нейтральными словами также значимы (0.0457 < 0.05).

Самый интересный вывод — нейтральная коннотация выделяется по длине слов. Это может означать, что нейтральные термины короче/длиннее по сравнению с стальными. Остальные эмоциональные категории — положительные, отрицательные, ироничные и амбивалентные — не сильно различаются между собой по длине слов.


Чтобы точно определить, короче или длиннее нейтральные слова по сравнению с другими типами коннотации, проведу сравнение медиан:

```{r median_comparison}
df %>%
  group_by(Connotation) %>%
  summarise(
    Median = median(word_length),
    Mean = mean(word_length),
    SD = sd(word_length)
  ) %>%
  arrange(Median)
```
Ключевые закономерности:
Нейтральные термины существенно короче всех остальных.
Позитивные термины занимают промежуточное положение.
Негативные, ироничные и амбивалентные термины самые длинные.

Подтверждается ранее полученными тестами:
Все сравнения нейтральных слов с другими типами коннотации были статистически значимыми (p < 0.05). Различия между негативными, ироничными и амбивалентными терминами незначимы.


Для проверки зависимости между категориальными переменными, проводится тест хи-квадрат, так как данных достаточно много и тест Фишера будет неэффектиным.

```{r xi_test}
# Тест хи-квадрат 
# связь коннотации и жанра
chisq.test(table(df$Connotation, 
                df$Genre.of.game.Where.it.appears))

#Гипотеза: коннотация зависит от контекста
chisq.test(table(df$context, df$Connotation))


# связь коннотации и модели словообразования
chisq.test(table(df$Connotation, df$word.formation.model))

# связь коннотации и части речи
chisq.test(table(df$Connotation, df$part.of.speech))
```
Интерпретация результатов теста хи-квадрат.

Коннотация и жанр игры: 
p > 0.05, значит, нет статистически значимой связи, жанр игры не влияет на коннотацию слова.

Коннотация и контекст: 
p < 0.001, значит, очень сильная статистическая связь, контекст использования игрового сленга существенно влияет на коннотацию.

Коннотация и словообразовательная модель: 
p < 0.001, значит, существенная зависимость, модель словообразования влияет на коннотацию.

Коннотация и часть речи: 
p = 0.004222 < 0.05, значит, мы отвергаем H0, есть статистически значимая связь, коннотация слова зависит от части речи.


## Корреляционный анализ

```{r corr}
# Таблица сопряжённости
tbl <- table(df$Connotation, df$context)

# Cramér's V
assocstats(tbl)

# Мозаичный график
mosaicplot(tbl,
           main = "Связь между контекстом и коннотацией",
           color = TRUE,
           shade = TRUE,
           las = 2,
           cex.axis = 0.8)


ggplot(data = df) +
  geom_mosaic(aes(weight = 1, x = product(context), fill = Connotation)) +
  labs(x = "Контекст", y = "Доля", fill = "Коннотация") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

Умеренная связь между переменными. Переменные context и Connotation зависимы. Связь статистически значимая.

## Регрессионный анализ
Цель: проверить, влияют ли коннотация, контекст, словообразовательная модель на длину слова.
```{r lm}
model <- lm(word_length ~ Connotation + context + word.formation.model, data = df)
summary(model)

par(mfrow = c(2,2))
plot(model)
```
Тип модели словообразования — ключевой фактор, объясняющий длину слова. Конотация и контекст сами по себе не дают значимого вклада. Следующие модели словообразования значимо увеличивают длину слов: Word composition, Spoonerisms, Reduplication.

-------

В рамках данного проекта была разработана модель для предсказания коннотации игрового сленга.
Цель модели: разработать классификатор, способный автоматически определять коннотацию игрового сленга на основе текстовых признаков, включая контекст использования, жанр игры, часть речи и модель словообразования.

Модель должна помочь: автоматически анализировать тональность игровых терминов, улучшить модерацию чатов в онлайн-играх, исследовать закономерности использования сленга.

Задачи модели:
1. Предобработка данных: текстовая очистка, объединение признаков, обработка пропусков.
2. Балансировка данных: Oversampling и использование upSample() для устранения дисбаланса классов.
3. Векторизация текста (TF-IDF): токенизация, разбиение текста на слова и биграммы, построение словаря, отбор частотных терминов, преобразование в матрицу.
4. Обучение модели: логистическая регрессия (многоклассовая классификация) с регуляризацией (Elastic Net).
5. Оценка качества.

```{r prediction}
# 1. Предобработка данных

# Очистка текста
clean_text <- function(text) {
  text %>%
    tolower() %>%
    stringi::stri_trans_general("Latin-ASCII") %>%
    str_replace_all("[^a-z0-9!? ]", " ") %>%
    str_squish()
}

# Объединение признаков
df$combined_text <- df %>%
  mutate(
    combined_text = paste(
      clean_text(Sentence),
      clean_text(part.of.speech),
      clean_text(Genre.of.game.Where.it.appears),
      clean_text(context),
      clean_text(word.formation.model)
    ) %>% str_squish()
  ) %>%
  pull(combined_text)

# NA
df_clean <- df %>% filter(!is.na(combined_text), !is.na(Connotation))

# 2. Балансировка данных
# Oversampling
set.seed(123)
upsampled_data <- upSample(
  x = df_clean["combined_text"],
  y = df_clean$Connotation,
  yname = "Connotation"
)

# Разделение данных
set.seed(123)
train_index <- createDataPartition(upsampled_data$Connotation, p = 0.8, list = FALSE)
train_data <- upsampled_data[train_index, ]
test_data <- upsampled_data[-train_index, ]

#3. Векторизация текста (TF-IDF)
tokens <- itoken(train_data$combined_text, tokenizer = word_tokenizer, progressbar = FALSE)
vocab <- create_vocabulary(tokens, ngram = c(1, 2)) %>%
  prune_vocabulary(term_count_min = 5)  # фильтрация редких

vectorizer <- vocab_vectorizer(vocab)

dtm_train <- create_dtm(tokens, vectorizer)
tfidf <- TfIdf$new()
dtm_train_tfidf <- fit_transform(dtm_train, tfidf)

# 4. Обучение модели
# Преобразование тестовой выборки
test_tokens <- itoken(test_data$combined_text,
                      tokenizer = word_tokenizer,
                      progressbar = FALSE)


dtm_test <- create_dtm(test_tokens, vectorizer)
dtm_test_tfidf <- transform(dtm_test, tfidf)

# Модель
model <- cv.glmnet(
  x = dtm_train_tfidf,
  y = train_data$Connotation,
  family = "multinomial",
  type.measure = "class",
  alpha = 0.5
)

# 5. Предсказания и оценка
preds <- predict(model, dtm_test_tfidf, s = "lambda.min", type = "class")
confusionMatrix(as.factor(preds), test_data$Connotation)
```

Accuracy = 66% - модель показывает точность выше случайного угадывания
Kappa = 0.575 — умеренное согласие модели с истинными метками.
F1 ≈ 0.67

Анализ метрик:
Для класса ambivalent: модель находит 60% реальных ambivalent случаев.
Для класса irony/sarcasm: высокая Sensitivity, но слабая Precision: модель часто предсказывает иронию ошибочно.
Для класса negative: отличная Precision ((нет ложных срабатываний), но малая Sensitivity. 
Для класса neutral: хороший баланс.
Для класса positive: слабее neutral, но лучше irony.

Наблюдения: 
Классы "negative" и "neutral" имеют наименьшее количество ошибок
Классы "irony/sarcasm" и "positive" часто путаются между собой и с другими классами
Класс "negative" не имеет ложных срабатываний (все 6 предсказаний верны)
Модель хорошо отличает negative и neutral.

Вывод:
Модель демонстрирует хороший базовый уровень классификации, но требует доработки в области различения близких по смыслу классов (особенно irony/sarcasm и positive). Наибольшие проблемы связаны с многозначностью некоторых игровых терминов и дисбалансом в классах. 

```{r pred_func}
# Функция для предсказания коннотации
predict_connotation <- function(sentence, model, vectorizer, tfidf) {
  token <- itoken(sentence,
                  preprocessor = tolower,
                  tokenizer = word_tokenizer,
                  progressbar = FALSE)
  
  dtm <- create_dtm(token, vectorizer)
  dtm_tfidf <- transform(dtm, tfidf)
  prediction <- predict(model, dtm_tfidf, s = "lambda.min", type = "class")
  return(as.character(prediction))
}
```


```{r pred_result}
# Предсказание коннотации предложения
predict_connotation("Press E to attack.", model, vectorizer, tfidf)
predict_connotation("That player is a total feeder.", model, vectorizer, tfidf)
predict_connotation("You are a top banger.", model, vectorizer, tfidf)
predict_connotation("Our team is a total clown fiesta.", model, vectorizer, tfidf)
predict_connotation("It is GG, guys.", model, vectorizer, tfidf)
predict_connotation("My new weapon imba", model, vectorizer, tfidf)
```


## Методы сокращения размерности

```{r mca}
#MCA (Анализ соответствий) для категориальных переменных
gaming_slang_mca <- df %>%
  select(part.of.speech, context, Genre.of.game.Where.it.appears, 
         word.formation.model) %>%
  mutate(across(everything(), as.factor))

mca_result <- MCA(gaming_slang_mca, ncp = 5, graph = TRUE)

# Визуализация

fviz_mca_ind(mca_result,
             label = "none", 
             habillage = df$Connotation,
             addEllipses = TRUE, 
             repel = TRUE,
             ggtheme = theme_minimal())

# Вклад переменных
fviz_mca_var(mca_result, choice = "mca.cor", repel = TRUE)

```

Интерпретация анализа соответствий:
График Variables-MCA отображает вклад переменных в мультикорреспондентный анализ (MCA). Он показывает, какие переменные сильнее всего связаны с главными компонентами (Dim1 и Dim2).

Самый сильный вклад имеют переменные word.formation.model и context, то есть, именно они наиболее информативны для различения значений признаков, в том числе и целевой переменной Connotation.

Умеренный вклад вносят переменные part.of.speech и Genre.of.game.Where.it.appears. Они могут дополнять различие между наблюдениями, но не доминируют в объяснении дисперсии.

Dim1 (7.2%) и Dim2 (6.3%) объясняют всего 13.5% дисперсии, и это мало, для достижения 50% объясненной дисперсии требуется 10 осей.

Для последующего анализа стоит акцентировать внимание на word.formation.model и context.
